[Step4] SAVE_ROOT=/scratch-shared/tc1proj005/folds FOLDS=[0, 1, 2, 3, 4] MODELS=['llama'] SAVE_LASTTOK=False TOPK=0
[Step4] Loaded data/fold_data/fold_0_train.csv rows=203656 cols=17
[Step4] Loaded data/fold_data/fold_0_val.csv rows=11496 cols=9
[Step4] Loading llama fold 0 from LoRA /scratch-shared/tc1proj005/folds/llama_fold_0_lora + base /scratch-shared/tc1proj005/post_pretrain_llama3-8b_merged
[Step4][Info] Tokenizer source for llama fold 0: /scratch-shared/tc1proj005/folds/llama_fold_0_lora
[Step4][Info] Accelerate device_map detected; skipping explicit model.to().
[Step4][Subset] llama fold 0: sampled 15428/203656 rows (seed offset).
[Step4] Using batched loglik batch_size=8 progress_every=50
[Step4][Progress] RespA fold batch 8/15428 (1.70 ex/s) elapsed=0.1m
[Step4][Progress] RespA fold batch 408/15428 (4.93 ex/s) elapsed=1.4m
[Step4][Progress] RespA fold batch 808/15428 (5.07 ex/s) elapsed=2.7m
[Step4][Progress] RespA fold batch 1208/15428 (5.22 ex/s) elapsed=3.9m
[Step4][Progress] RespA fold batch 1608/15428 (5.24 ex/s) elapsed=5.1m
[Step4][Progress] RespA fold batch 2008/15428 (5.28 ex/s) elapsed=6.3m
[Step4][Progress] RespA fold batch 2408/15428 (5.36 ex/s) elapsed=7.5m
[Step4][Progress] RespA fold batch 2808/15428 (5.31 ex/s) elapsed=8.8m
[Step4][Progress] RespA fold batch 3208/15428 (5.32 ex/s) elapsed=10.1m
[Step4][Progress] RespA fold batch 3608/15428 (5.32 ex/s) elapsed=11.3m
[Step4][Progress] RespA fold batch 4008/15428 (5.31 ex/s) elapsed=12.6m
[Step4][Progress] RespA fold batch 4408/15428 (5.33 ex/s) elapsed=13.8m
[Step4][Progress] RespA fold batch 4808/15428 (5.34 ex/s) elapsed=15.0m
[Step4][Progress] RespA fold batch 5208/15428 (5.36 ex/s) elapsed=16.2m
[Step4][Progress] RespA fold batch 5608/15428 (5.37 ex/s) elapsed=17.4m
[Step4][Progress] RespA fold batch 6008/15428 (5.36 ex/s) elapsed=18.7m
[Step4][Progress] RespA fold batch 6408/15428 (5.35 ex/s) elapsed=20.0m
[Step4][Progress] RespA fold batch 6808/15428 (5.32 ex/s) elapsed=21.3m
[Step4][Progress] RespA fold batch 7208/15428 (5.31 ex/s) elapsed=22.6m
[Step4][Progress] RespA fold batch 7608/15428 (5.34 ex/s) elapsed=23.7m
[Step4][Progress] RespA fold batch 8008/15428 (5.35 ex/s) elapsed=25.0m
[Step4][Progress] RespA fold batch 8408/15428 (5.31 ex/s) elapsed=26.4m
[Step4][Progress] RespA fold batch 8808/15428 (5.33 ex/s) elapsed=27.6m
[Step4][Progress] RespA fold batch 9208/15428 (5.33 ex/s) elapsed=28.8m
[Step4][Progress] RespA fold batch 9608/15428 (5.36 ex/s) elapsed=29.9m
[Step4][Progress] RespA fold batch 10008/15428 (5.37 ex/s) elapsed=31.1m
[Step4][Progress] RespA fold batch 10408/15428 (5.36 ex/s) elapsed=32.4m
[Step4][Progress] RespA fold batch 10808/15428 (5.35 ex/s) elapsed=33.6m
[Step4][Progress] RespA fold batch 11208/15428 (5.36 ex/s) elapsed=34.9m
[Step4][Progress] RespA fold batch 11608/15428 (5.35 ex/s) elapsed=36.2m
[Step4][Progress] RespA fold batch 12008/15428 (5.35 ex/s) elapsed=37.4m
[Step4][Progress] RespA fold batch 12408/15428 (5.36 ex/s) elapsed=38.6m
[Step4][Progress] RespA fold batch 12808/15428 (5.37 ex/s) elapsed=39.8m
[Step4][Progress] RespA fold batch 13208/15428 (5.36 ex/s) elapsed=41.1m
[Step4][Progress] RespA fold batch 13608/15428 (5.36 ex/s) elapsed=42.3m
[Step4][Progress] RespA fold batch 14008/15428 (5.36 ex/s) elapsed=43.5m
[Step4][Progress] RespA fold batch 14408/15428 (5.37 ex/s) elapsed=44.8m
[Step4][Progress] RespA fold batch 14808/15428 (5.36 ex/s) elapsed=46.0m
[Step4][Progress] RespA fold batch 15208/15428 (5.37 ex/s) elapsed=47.2m
[Step4][Progress] RespB fold batch 8/15428 (0.00 ex/s) elapsed=47.8m
[Step4][Progress] RespB fold batch 408/15428 (0.14 ex/s) elapsed=49.2m
[Step4][Progress] RespB fold batch 808/15428 (0.27 ex/s) elapsed=50.5m
[Step4][Progress] RespB fold batch 1208/15428 (0.39 ex/s) elapsed=51.6m
[Step4][Progress] RespB fold batch 1608/15428 (0.51 ex/s) elapsed=52.9m
[Step4][Progress] RespB fold batch 2008/15428 (0.62 ex/s) elapsed=54.1m
[Step4][Progress] RespB fold batch 2408/15428 (0.73 ex/s) elapsed=55.2m
[Step4][Progress] RespB fold batch 2808/15428 (0.83 ex/s) elapsed=56.5m
[Step4][Progress] RespB fold batch 3208/15428 (0.93 ex/s) elapsed=57.7m
[Step4][Progress] RespB fold batch 3608/15428 (1.02 ex/s) elapsed=59.0m
[Step4][Progress] RespB fold batch 4008/15428 (1.11 ex/s) elapsed=60.2m
[Step4][Progress] RespB fold batch 4408/15428 (1.20 ex/s) elapsed=61.4m
[Step4][Progress] RespB fold batch 4808/15428 (1.28 ex/s) elapsed=62.6m
[Step4][Progress] RespB fold batch 5208/15428 (1.36 ex/s) elapsed=63.8m
[Step4][Progress] RespB fold batch 5608/15428 (1.44 ex/s) elapsed=65.0m
[Step4][Progress] RespB fold batch 6008/15428 (1.51 ex/s) elapsed=66.3m
[Step4][Progress] RespB fold batch 6408/15428 (1.58 ex/s) elapsed=67.6m
[Step4][Progress] RespB fold batch 6808/15428 (1.64 ex/s) elapsed=69.0m
[Step4][Progress] RespB fold batch 7208/15428 (1.71 ex/s) elapsed=70.3m
[Step4][Progress] RespB fold batch 7608/15428 (1.78 ex/s) elapsed=71.4m
[Step4][Progress] RespB fold batch 8008/15428 (1.84 ex/s) elapsed=72.6m
[Step4][Progress] RespB fold batch 8408/15428 (1.90 ex/s) elapsed=73.9m
[Step4][Progress] RespB fold batch 8808/15428 (1.95 ex/s) elapsed=75.2m
[Step4][Progress] RespB fold batch 9208/15428 (2.01 ex/s) elapsed=76.4m
[Step4][Progress] RespB fold batch 9608/15428 (2.07 ex/s) elapsed=77.5m
[Step4][Progress] RespB fold batch 10008/15428 (2.12 ex/s) elapsed=78.7m
[Step4][Progress] RespB fold batch 10408/15428 (2.17 ex/s) elapsed=80.0m
[Step4][Progress] RespB fold batch 10808/15428 (2.22 ex/s) elapsed=81.3m
[Step4][Progress] RespB fold batch 11208/15428 (2.26 ex/s) elapsed=82.5m
[Step4][Progress] RespB fold batch 11608/15428 (2.31 ex/s) elapsed=83.9m
[Step4][Progress] RespB fold batch 12008/15428 (2.35 ex/s) elapsed=85.1m
[Step4][Progress] RespB fold batch 12408/15428 (2.40 ex/s) elapsed=86.3m
[Step4][Progress] RespB fold batch 12808/15428 (2.44 ex/s) elapsed=87.6m
[Step4][Progress] RespB fold batch 13208/15428 (2.48 ex/s) elapsed=88.9m
[Step4][Progress] RespB fold batch 13608/15428 (2.52 ex/s) elapsed=90.1m
[Step4][Progress] RespB fold batch 14008/15428 (2.56 ex/s) elapsed=91.3m
[Step4][Progress] RespB fold batch 14408/15428 (2.60 ex/s) elapsed=92.5m
[Step4][Progress] RespB fold batch 14808/15428 (2.63 ex/s) elapsed=93.8m
[Step4][Progress] RespB fold batch 15208/15428 (2.67 ex/s) elapsed=95.0m
[Step4] Saved tensor -> model_save/teacher_logits/llama_fold_0_train_logprobs.pt shape=(15428, 3)
[Step4] Saved tensor -> model_save/teacher_logits/llama_fold_0_train_probs.pt shape=(15428, 3)
[Step4] (val) Using batched loglik batch_size=8 progress_every=50
[Step4][Progress] RespA fold batch 8/11496 (3.25 ex/s) elapsed=0.0m
[Step4][Progress] RespA fold batch 408/11496 (3.92 ex/s) elapsed=1.7m
[Step4][Progress] RespA fold batch 808/11496 (4.00 ex/s) elapsed=3.4m
[Step4][Progress] RespA fold batch 1208/11496 (3.99 ex/s) elapsed=5.0m
[Step4][Progress] RespA fold batch 1608/11496 (4.05 ex/s) elapsed=6.6m
[Step4][Progress] RespA fold batch 2008/11496 (4.08 ex/s) elapsed=8.2m
[Step4][Progress] RespA fold batch 2408/11496 (4.05 ex/s) elapsed=9.9m
[Step4][Progress] RespA fold batch 2808/11496 (4.03 ex/s) elapsed=11.6m
[Step4][Progress] RespA fold batch 3208/11496 (4.06 ex/s) elapsed=13.2m
[Step4][Progress] RespA fold batch 3608/11496 (4.05 ex/s) elapsed=14.9m
[Step4][Progress] RespA fold batch 4008/11496 (4.02 ex/s) elapsed=16.6m
[Step4][Progress] RespA fold batch 4408/11496 (4.01 ex/s) elapsed=18.3m
[Step4][Progress] RespA fold batch 4808/11496 (4.02 ex/s) elapsed=19.9m
[Step4][Progress] RespA fold batch 5208/11496 (4.03 ex/s) elapsed=21.5m
[Step4][Progress] RespA fold batch 5608/11496 (4.02 ex/s) elapsed=23.2m
[Step4][Progress] RespA fold batch 6008/11496 (4.04 ex/s) elapsed=24.8m
[Step4][Progress] RespA fold batch 6408/11496 (4.03 ex/s) elapsed=26.5m
[Step4][Progress] RespA fold batch 6808/11496 (4.04 ex/s) elapsed=28.1m
[Step4][Progress] RespA fold batch 7208/11496 (4.03 ex/s) elapsed=29.8m
[Step4][Progress] RespA fold batch 7608/11496 (4.03 ex/s) elapsed=31.5m
[Step4][Progress] RespA fold batch 8008/11496 (4.04 ex/s) elapsed=33.0m
[Step4][Progress] RespA fold batch 8408/11496 (4.05 ex/s) elapsed=34.6m
[Step4][Progress] RespA fold batch 8808/11496 (4.04 ex/s) elapsed=36.3m
[Step4][Progress] RespA fold batch 9208/11496 (4.04 ex/s) elapsed=38.0m
[Step4][Progress] RespA fold batch 9608/11496 (4.06 ex/s) elapsed=39.5m
[Step4][Progress] RespA fold batch 10008/11496 (4.05 ex/s) elapsed=41.1m
[Step4][Progress] RespA fold batch 10408/11496 (4.05 ex/s) elapsed=42.8m
[Step4][Progress] RespA fold batch 10808/11496 (4.06 ex/s) elapsed=44.4m
[Step4][Progress] RespA fold batch 11208/11496 (4.06 ex/s) elapsed=46.1m
[Step4][Progress] RespB fold batch 8/11496 (0.00 ex/s) elapsed=47.3m
[Step4][Progress] RespB fold batch 408/11496 (0.14 ex/s) elapsed=49.1m
[Step4][Progress] RespB fold batch 808/11496 (0.27 ex/s) elapsed=50.7m
[Step4][Progress] RespB fold batch 1208/11496 (0.38 ex/s) elapsed=52.4m
[Step4][Progress] RespB fold batch 1608/11496 (0.50 ex/s) elapsed=54.0m
[Step4][Progress] RespB fold batch 2008/11496 (0.60 ex/s) elapsed=55.5m
[Step4][Progress] RespB fold batch 2408/11496 (0.70 ex/s) elapsed=57.2m
[Step4][Progress] RespB fold batch 2808/11496 (0.80 ex/s) elapsed=58.8m
[Step4][Progress] RespB fold batch 3208/11496 (0.89 ex/s) elapsed=60.3m
[Step4][Progress] RespB fold batch 3608/11496 (0.97 ex/s) elapsed=62.0m
[Step4][Progress] RespB fold batch 4008/11496 (1.05 ex/s) elapsed=63.8m
[Step4][Progress] RespB fold batch 4408/11496 (1.12 ex/s) elapsed=65.4m
[Step4][Progress] RespB fold batch 4808/11496 (1.20 ex/s) elapsed=67.0m
[Step4][Progress] RespB fold batch 5208/11496 (1.26 ex/s) elapsed=68.7m
[Step4][Progress] RespB fold batch 5608/11496 (1.33 ex/s) elapsed=70.4m
[Step4][Progress] RespB fold batch 6008/11496 (1.39 ex/s) elapsed=71.9m
[Step4][Progress] RespB fold batch 6408/11496 (1.45 ex/s) elapsed=73.6m
[Step4][Progress] RespB fold batch 6808/11496 (1.51 ex/s) elapsed=75.2m
[Step4][Progress] RespB fold batch 7208/11496 (1.56 ex/s) elapsed=76.9m
[Step4][Progress] RespB fold batch 7608/11496 (1.61 ex/s) elapsed=78.7m
[Step4][Progress] RespB fold batch 8008/11496 (1.66 ex/s) elapsed=80.3m
[Step4][Progress] RespB fold batch 8408/11496 (1.71 ex/s) elapsed=82.0m
[Step4][Progress] RespB fold batch 8808/11496 (1.76 ex/s) elapsed=83.6m
[Step4][Progress] RespB fold batch 9208/11496 (1.80 ex/s) elapsed=85.3m
[Step4][Progress] RespB fold batch 9608/11496 (1.84 ex/s) elapsed=86.8m
[Step4][Progress] RespB fold batch 10008/11496 (1.88 ex/s) elapsed=88.5m
[Step4][Progress] RespB fold batch 10408/11496 (1.92 ex/s) elapsed=90.2m
[Step4][Progress] RespB fold batch 10808/11496 (1.96 ex/s) elapsed=91.9m
[Step4][Progress] RespB fold batch 11208/11496 (2.00 ex/s) elapsed=93.6m
[Step4] Saved tensor -> model_save/teacher_logits/llama_fold_0_val_logprobs.pt shape=(11496, 3)
[Step4] Saved tensor -> model_save/teacher_logits/llama_fold_0_val_probs.pt shape=(11496, 3)
[Step4] Loaded data/fold_data/fold_1_train.csv rows=203656 cols=17
[Step4] Loaded data/fold_data/fold_1_val.csv rows=11496 cols=9
[Step4] Loading llama fold 1 from LoRA /scratch-shared/tc1proj005/folds/llama_fold_1_lora + base /scratch-shared/tc1proj005/post_pretrain_llama3-8b_merged
[Step4][Info] Tokenizer source for llama fold 1: /scratch-shared/tc1proj005/folds/llama_fold_1_lora
