`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:04<01:14,  4.97s/it]Loading checkpoint shards:  12%|█▎        | 2/16 [00:14<01:45,  7.51s/it]Loading checkpoint shards:  19%|█▉        | 3/16 [00:21<01:33,  7.17s/it]Loading checkpoint shards:  25%|██▌       | 4/16 [00:27<01:21,  6.78s/it]Loading checkpoint shards:  31%|███▏      | 5/16 [00:31<01:04,  5.89s/it]Loading checkpoint shards:  38%|███▊      | 6/16 [00:45<01:25,  8.53s/it]Loading checkpoint shards:  44%|████▍     | 7/16 [00:50<01:07,  7.55s/it]Loading checkpoint shards:  50%|█████     | 8/16 [00:54<00:51,  6.49s/it]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:59<00:41,  5.92s/it]Loading checkpoint shards:  62%|██████▎   | 10/16 [01:04<00:33,  5.62s/it]Loading checkpoint shards:  69%|██████▉   | 11/16 [01:09<00:26,  5.32s/it]Loading checkpoint shards:  75%|███████▌  | 12/16 [01:13<00:20,  5.10s/it]Loading checkpoint shards:  81%|████████▏ | 13/16 [01:19<00:16,  5.36s/it]Loading checkpoint shards:  88%|████████▊ | 14/16 [01:24<00:10,  5.03s/it]Loading checkpoint shards:  94%|█████████▍| 15/16 [01:28<00:04,  4.96s/it]Loading checkpoint shards: 100%|██████████| 16/16 [01:30<00:00,  3.89s/it]Loading checkpoint shards: 100%|██████████| 16/16 [01:30<00:00,  5.64s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /scratch-shared/tc1proj005/post_pretrain_llama3-8b_merged and are newly initialized: ['lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
