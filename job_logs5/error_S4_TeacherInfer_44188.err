`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:08<02:12,  8.85s/it]Loading checkpoint shards:  12%|█▎        | 2/16 [00:28<03:30, 15.03s/it]Loading checkpoint shards:  19%|█▉        | 3/16 [00:47<03:42, 17.11s/it]Loading checkpoint shards:  25%|██▌       | 4/16 [01:03<03:17, 16.46s/it]Loading checkpoint shards:  31%|███▏      | 5/16 [01:10<02:25, 13.23s/it]Loading checkpoint shards:  38%|███▊      | 6/16 [01:18<01:52, 11.20s/it]Loading checkpoint shards:  44%|████▍     | 7/16 [01:28<01:38, 10.96s/it]Loading checkpoint shards:  50%|█████     | 8/16 [01:38<01:25, 10.65s/it]Loading checkpoint shards:  56%|█████▋    | 9/16 [01:48<01:12, 10.42s/it]Loading checkpoint shards:  62%|██████▎   | 10/16 [01:58<01:01, 10.27s/it]Loading checkpoint shards:  69%|██████▉   | 11/16 [02:09<00:52, 10.43s/it]Loading checkpoint shards:  75%|███████▌  | 12/16 [02:16<00:37,  9.45s/it]Loading checkpoint shards:  81%|████████▏ | 13/16 [02:25<00:27,  9.22s/it]Loading checkpoint shards:  88%|████████▊ | 14/16 [02:32<00:17,  8.80s/it]Loading checkpoint shards:  94%|█████████▍| 15/16 [02:43<00:09,  9.22s/it]Loading checkpoint shards: 100%|██████████| 16/16 [02:45<00:00,  7.25s/it]Loading checkpoint shards: 100%|██████████| 16/16 [02:45<00:00, 10.36s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /scratch-shared/tc1proj005/post_pretrain_llama3-8b_merged and are newly initialized: ['lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
