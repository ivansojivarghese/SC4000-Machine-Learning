[Step5] Distilling fold 0 using LLaMA-only OOF probs
{'loss': 2.0992, 'grad_norm': 23.225404739379883, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.03}
{'loss': 1.71, 'grad_norm': 11.318427085876465, 'learning_rate': 4.792553191489362e-05, 'epoch': 0.06}
{'loss': 1.5622, 'grad_norm': 17.179027557373047, 'learning_rate': 4.526595744680851e-05, 'epoch': 0.09}
{'loss': 1.388, 'grad_norm': 4.957003116607666, 'learning_rate': 4.2606382978723406e-05, 'epoch': 0.12}
{'loss': 1.3392, 'grad_norm': 14.169466972351074, 'learning_rate': 3.99468085106383e-05, 'epoch': 0.15}
{'loss': 1.383, 'grad_norm': 7.067108631134033, 'learning_rate': 3.728723404255319e-05, 'epoch': 0.18}
{'loss': 1.2853, 'grad_norm': 8.537347793579102, 'learning_rate': 3.462765957446809e-05, 'epoch': 0.21}
{'loss': 1.3152, 'grad_norm': 13.215204238891602, 'learning_rate': 3.1968085106382976e-05, 'epoch': 0.24}
{'loss': 1.307, 'grad_norm': 10.606236457824707, 'learning_rate': 2.9308510638297876e-05, 'epoch': 0.27}
{'loss': 1.2588, 'grad_norm': 10.77193546295166, 'learning_rate': 2.664893617021277e-05, 'epoch': 0.3}
{'loss': 1.2536, 'grad_norm': 2.5771381855010986, 'learning_rate': 2.398936170212766e-05, 'epoch': 0.33}
{'loss': 1.2399, 'grad_norm': 9.78963565826416, 'learning_rate': 2.1329787234042554e-05, 'epoch': 0.36}
{'loss': 1.216, 'grad_norm': 5.495971202850342, 'learning_rate': 1.867021276595745e-05, 'epoch': 0.39}
{'loss': 1.213, 'grad_norm': 9.350743293762207, 'learning_rate': 1.6010638297872342e-05, 'epoch': 0.42}
{'loss': 1.2163, 'grad_norm': 9.985610961914062, 'learning_rate': 1.3351063829787237e-05, 'epoch': 0.45}
{'loss': 1.2078, 'grad_norm': 4.359248161315918, 'learning_rate': 1.0691489361702128e-05, 'epoch': 0.48}
{'loss': 1.2096, 'grad_norm': 12.872536659240723, 'learning_rate': 8.031914893617022e-06, 'epoch': 0.51}
{'loss': 1.2222, 'grad_norm': 7.627667427062988, 'learning_rate': 5.372340425531915e-06, 'epoch': 0.54}
{'loss': 1.1837, 'grad_norm': 9.991615295410156, 'learning_rate': 2.7127659574468088e-06, 'epoch': 0.57}
{'loss': 1.1645, 'grad_norm': 5.07765531539917, 'learning_rate': 5.319148936170213e-08, 'epoch': 0.6}
{'train_runtime': 14647.8662, 'train_samples_per_second': 2.185, 'train_steps_per_second': 0.068, 'train_loss': 1.3387189903259278, 'epoch': 0.6}
{'eval': {'eval_loss': 0.2937629520893097, 'eval_log_loss': 0.9650644200143466, 'eval_accuracy': 0.5254579062342464, 'eval_runtime': 843.1593, 'eval_samples_per_second': 7.058, 'eval_steps_per_second': 0.882, 'epoch': 0.5974607916355489}}
[Step5] Exporting classifier head to model_save/distilled_gemma2-9b_fold_0/classifier_head.pt
{'saved': 'model_save/distilled_gemma2-9b_fold_0/classifier_head.pt'}
[Step5] Done fold 0 -> model_save/distilled_gemma2-9b_fold_0
