[Step5] Distilling fold 2 using LLaMA-only OOF probs
{'loss': 5.7039, 'grad_norm': 51.90165328979492, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.03}
{'loss': 5.0602, 'grad_norm': 45.86272430419922, 'learning_rate': 4.792553191489362e-05, 'epoch': 0.06}
{'loss': 4.7728, 'grad_norm': 28.992380142211914, 'learning_rate': 4.526595744680851e-05, 'epoch': 0.09}
{'loss': 4.7238, 'grad_norm': 45.734622955322266, 'learning_rate': 4.2606382978723406e-05, 'epoch': 0.12}
{'loss': 4.4524, 'grad_norm': 31.824703216552734, 'learning_rate': 3.99468085106383e-05, 'epoch': 0.15}
{'loss': 4.4878, 'grad_norm': 50.30721664428711, 'learning_rate': 3.728723404255319e-05, 'epoch': 0.18}
{'loss': 4.3484, 'grad_norm': 38.03302764892578, 'learning_rate': 3.462765957446809e-05, 'epoch': 0.21}
{'loss': 4.1506, 'grad_norm': 36.721275329589844, 'learning_rate': 3.1968085106382976e-05, 'epoch': 0.24}
{'loss': 4.6652, 'grad_norm': 17.072525024414062, 'learning_rate': 2.9308510638297876e-05, 'epoch': 0.27}
{'loss': 4.4302, 'grad_norm': 23.741939544677734, 'learning_rate': 2.664893617021277e-05, 'epoch': 0.3}
{'loss': 4.4462, 'grad_norm': 10.478582382202148, 'learning_rate': 2.398936170212766e-05, 'epoch': 0.33}
{'loss': 4.3741, 'grad_norm': 14.118067741394043, 'learning_rate': 2.1329787234042554e-05, 'epoch': 0.36}
{'loss': 4.3265, 'grad_norm': 24.838163375854492, 'learning_rate': 1.867021276595745e-05, 'epoch': 0.39}
{'loss': 4.4378, 'grad_norm': 15.349995613098145, 'learning_rate': 1.6010638297872342e-05, 'epoch': 0.42}
{'loss': 4.3667, 'grad_norm': 31.516321182250977, 'learning_rate': 1.3351063829787237e-05, 'epoch': 0.45}
{'loss': 4.4852, 'grad_norm': 20.7780704498291, 'learning_rate': 1.0691489361702128e-05, 'epoch': 0.48}
{'loss': 4.4372, 'grad_norm': 62.83866500854492, 'learning_rate': 8.031914893617022e-06, 'epoch': 0.51}
{'loss': 4.5101, 'grad_norm': 22.29763412475586, 'learning_rate': 5.372340425531915e-06, 'epoch': 0.54}
{'loss': 4.3919, 'grad_norm': 28.14859962463379, 'learning_rate': 2.7127659574468088e-06, 'epoch': 0.57}
{'loss': 4.432, 'grad_norm': 29.99502944946289, 'learning_rate': 5.319148936170213e-08, 'epoch': 0.6}
{'train_runtime': 14510.1639, 'train_samples_per_second': 2.205, 'train_steps_per_second': 0.069, 'train_loss': 4.550158218383789, 'epoch': 0.6}
{'eval': {'eval_loss': 1.0924203395843506, 'eval_log_loss': 1.265655801044073, 'eval_accuracy': 0.39707612166022516, 'eval_runtime': 807.1561, 'eval_samples_per_second': 7.373, 'eval_steps_per_second': 0.922, 'epoch': 0.5974607916355489}}
[Step5] Exporting classifier head to model_save/distilled_gemma2-9b_fold_2/classifier_head.pt
{'saved': 'model_save/distilled_gemma2-9b_fold_2/classifier_head.pt'}
[Step5] Done fold 2 -> model_save/distilled_gemma2-9b_fold_2
